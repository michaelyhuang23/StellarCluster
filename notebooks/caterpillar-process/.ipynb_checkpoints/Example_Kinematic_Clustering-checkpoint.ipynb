{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#plotly is better than matplotlib at plotting large datasets\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import seaborn as sns # has some nice plotting options\n",
    "import haloutils\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 # the databases are SQLite databases\n",
    "from sqlite3 import Error\n",
    "import random\n",
    "\n",
    "# clustering algorithms\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation, MeanShift, estimate_bandwidth\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import hdbscan\n",
    "import pyfof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful functions\n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "\n",
    "    db_file: database file\n",
    "\n",
    "    return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return None\n",
    "\n",
    "def get_host_props(hpath,snap):\n",
    "    \"\"\" returns information about a given halo at a given snapshot\n",
    "    \n",
    "    hpath: file path of the halo\n",
    "    snap: snapshot number\n",
    "    \n",
    "    return: position of the halo, \n",
    "            velocity of the halo, \n",
    "            the total angular momentum of the halo\n",
    "    \"\"\"\n",
    "    mainbranch = haloutils.get_main_branch(hpath)\n",
    "    header = haloutils.get_halo_header(hpath)\n",
    "    mask = (snap == mainbranch['snap'])\n",
    "    hpos = np.array([mainbranch['posX'][mask],mainbranch['posY'][mask],mainbranch['posZ'][mask]])/header.hubble\n",
    "    hvel = np.array([mainbranch['pecVX'][mask],mainbranch['pecVY'][mask],mainbranch['pecVZ'][mask]])\n",
    "    hL = np.array([mainbranch['Jx'][mask],mainbranch['Jy'][mask],mainbranch['Jz'][mask]])\n",
    "\n",
    "    return hpos.T,hvel.T,hL\n",
    "\n",
    "def calcE(dvel,PE):\n",
    "    \"\"\"\n",
    "    dvel = halocentric velocity of particle in km/s\n",
    "    PE = peculiar potential energy of particle in (km/s)^2\n",
    "    \"\"\"\n",
    "    dV = np.sqrt(np.sum(dvel**2.)) # km/s\n",
    "    KE = 0.5*dV**2.\n",
    "\n",
    "    return KE + PE\n",
    "\n",
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    \n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "def rotmat_L_to_z(L):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix that rotates the coordinate frame\n",
    "    such that the new z vector, (0,0,1), aligns with L\n",
    "    \"\"\"\n",
    "    z0 = np.array([0,0,1])\n",
    "    l = L/np.linalg.norm(L) # normalizing\n",
    "    theta = np.arccos(np.dot(l,z0)) # rotation angle\n",
    "    axis = np.cross(l,z0) # rotation axis\n",
    "    \n",
    "    return rotation_matrix(axis,theta)\n",
    "\n",
    "def calcL(r,v):\n",
    "    \"\"\"\n",
    "    calculates total angular momentum, L\n",
    "    \"\"\"\n",
    "    return np.cross(r,v)\n",
    "\n",
    "def calcStats(x):\n",
    "    \"\"\"\n",
    "    Given an array, calculates the average, median, and 16th & 84th percentile values\n",
    "    \"\"\"\n",
    "    av = np.average(x)\n",
    "    med = np.median(x)\n",
    "    sigm = np.diff(np.percentile(x,[50-68/2, 50, 50+68/2]))\n",
    "    \n",
    "    return av, med, sigm[0], sigm[1]\n",
    "\n",
    "def snapToColor(snap,all_snaps,n_cmap=50):\n",
    "    \"\"\"\n",
    "    maps a given snapshot number to a corresponding color in a color map for plotting\n",
    "    \"\"\"\n",
    "    \n",
    "    cmap = sns.cubehelix_palette(n_cmap)\n",
    "    min_snap = min(all_snaps)\n",
    "    n_snap = max(all_snaps) - min_snap\n",
    "\n",
    "    c_index = int(np.round(n_cmap*(snap-min_snap)/n_snap)) - 1\n",
    "    \n",
    "    return cmap[c_index]\n",
    "\n",
    "def calcJtheta(Lx,Ly,Lz):\n",
    "    \"\"\"\n",
    "    calculates J_theta = |L| - Lz\n",
    "    \"\"\"\n",
    "    return np.sqrt(Lx**2 + Ly**2 + Lz**2) - Lz\n",
    "\n",
    "def normToCluster(df):\n",
    "    \"\"\"\n",
    "    normalizes a dataframe, which is necessary before using clustering algorithms\n",
    "    \"\"\"\n",
    "    x = df.values #returns a numpy array\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled,columns=df.columns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are ALL of the simulation IDs\n",
    "hids = \\\n",
    "    [1631506, 1725139,  447649,    5320,  581141, 1130025, 1387186,  581180,  264569,\n",
    "     1354437, 1725272, 1195448, 1292085,  796175,  388476, 1079897,   94638,   95289,\n",
    "     1232164, 1422331,  196589, 1268839, 1599988, 1195075, 1631582, 1422429,   65777,\n",
    "     1232423,  196078, 1599902,  795802, 1104787]\n",
    "\n",
    "hid = 1195448 # the halo ID of the simulation you want to use\n",
    "lx = 14 # the resolution of the simulation (only use LX14 resolution!)\n",
    "\n",
    "# quantities relevant to the current simulation\n",
    "hpath = haloutils.get_hpath_lx(hid,lx)\n",
    "hpos,hvel,hL = get_host_props(hpath,haloutils.get_lastsnap(hpath))\n",
    "hpos = hpos[0]\n",
    "hvel = hvel[0]\n",
    "hL = hL.T[0]\n",
    "rotmat = rotmat_L_to_z(hL)\n",
    "h0 = 0.69\n",
    "\n",
    "# connecting to kinematics database\n",
    "database = \"/blender/data/kbrauer/analysis/caterpillar/kinematics/LX\"+str(lx)+\"/H\"+str(hid)+\".db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "# defining some math functions for querying kinematics database\n",
    "conn.create_function('POWER', 2, np.power)\n",
    "conn.create_function('SQRT', 1, np.sqrt)\n",
    "\n",
    "# connecting to the destroyed halo database as well\n",
    "dh_database = \"/blender/data/kbrauer/analysis/caterpillar/destroyed_halos/LX\"+str(lx)+\"/H\"+str(hid)+\".db\"\n",
    "dh_conn = create_connection(dh_database)\n",
    "dh_cur = dh_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking a location 8 kpc from the center + perpendicular to L to act as the sun's location\n",
    "invmat = np.linalg.inv(rotmat)\n",
    "sun_pos = hpos + np.dot(invmat,np.array([0.008,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different mass bins for plotting stars from different mass halos\n",
    "# e.g., halos with masses between 5e7 Msun and 1e9 Msun can be considered \"ultra faint dwarfs\"\n",
    "# divide all of these values by \"little h\" to match simulation values\n",
    "# (more about little h: https://arxiv.org/abs/1308.4150)\n",
    "hMass_bins = np.array([5e7/h0,1e9/h0,1e10/h0,10**10.5/h0,1e11/h0,1e15])\n",
    "\n",
    "\"\"\" pick a radius cutoff \"\"\"\n",
    "radius = 0.01 # 10 kpc, optimistic parallax measurements\n",
    "# radius = 0.05 # 50 kpc, where stellar halo drops off\n",
    "# radius = 100 # include everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the actions for each tagged particle\n",
    "# from the kinematics database\n",
    "\n",
    "def extractActions(conn, lowMass, highMass, sun_pos, hpos, hvel, rotmat, radius, verbose=False):\n",
    "    c1 = conn.cursor()\n",
    "    c2 = conn.cursor()\n",
    "    n = c2.execute(\"SELECT COUNT(*) FROM kinematics WHERE halo_mass/0.7 > ? AND halo_mass/0.7 <= ? AND SQRT(POWER(ABS(x - ?),2) + POWER(ABS(y - ?),2) + POWER(ABS(z - ?),2)) < ?\", (lowMass, highMass, sun_pos[0], sun_pos[1], sun_pos[2], radius)).fetchone()[0]\n",
    "    print(\"particles: \"+str(n))\n",
    "    print(\"total halos: \"+str(dh_cur.execute(\"SELECT COUNT(*) FROM dHalo WHERE mass_peak/0.7 <= ? AND mass_peak/0.7 > ?\", (highMass, lowMass)).fetchone()[0]))\n",
    "\n",
    "    Lz = np.zeros(n)\n",
    "    Ltot = np.zeros(n)\n",
    "    E = np.zeros(n)\n",
    "    Jtheta = np.zeros(n)\n",
    "    v = np.zeros(n)\n",
    "    snap = np.zeros(n)\n",
    "    rsids = np.zeros(n)\n",
    "    pos = np.zeros((n,3))\n",
    "    vel = np.zeros((n,3))\n",
    "    mass = np.zeros(n)\n",
    "\n",
    "    i = 0\n",
    "    for row in c1.execute(\"SELECT vx, vy, vz, x, y, z, E, snap_infall, rsid, halo_mass FROM kinematics WHERE halo_mass/0.7 > ? AND halo_mass/0.7 <= ? AND SQRT(POWER(ABS(x - ?),2) + POWER(ABS(y - ?),2) + POWER(ABS(z - ?),2)) < ?\", (lowMass, highMass, sun_pos[0], sun_pos[1], sun_pos[2], radius)):\n",
    "        vx, vy, vz, x, y, z, PE, snap_infall, rsid, halo_mass = row\n",
    "\n",
    "        dvel = np.array([vx,vy,vz]) - hvel\n",
    "        dr = np.array([x,y,z]) - hpos\n",
    "        L = calcL(dr,dvel)\n",
    "        rotL = np.dot(rotmat,L.T)\n",
    "\n",
    "        E[i] = calcE(dvel,PE)\n",
    "        Jtheta[i] = np.sqrt(rotL[0]**2. + rotL[1]**2. + rotL[2]**2.) - np.abs(rotL[2])\n",
    "        Lz[i] = rotL[2]\n",
    "        Ltot[i] = np.sqrt(rotL[0]**2. + rotL[1]**2. + rotL[2]**2.)\n",
    "        v[i] = np.sqrt(np.sum(dvel**2.))\n",
    "        snap[i] = snap_infall\n",
    "        rsids[i] = rsid\n",
    "        pos[i][:] = dr\n",
    "        vel[i][:] = dvel\n",
    "        mass[i] = halo_mass\n",
    "        i += 1\n",
    "\n",
    "        if verbose and np.mod(i,1000) == 0:\n",
    "            print('completed '+ str(i))\n",
    "                          \n",
    "    print(\"halos in query volume: \" + str(len(np.unique(mass))))\n",
    "    \n",
    "    return Lz, Ltot, E, Jtheta, v, snap, rsids, pos, vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making some arrays to hold the actions for particles that\n",
    "# originated in different halo mass bins\n",
    "\n",
    "print(\"FIRST BIN -- UFDs\")\n",
    "Lz0, Ltot0, E0, Jtheta0, v0, snap0, rsid0, pos0, vel0 = extractActions(conn, hMass_bins[0], hMass_bins[1], sun_pos, hpos, hvel, rotmat, radius)\n",
    "print(\"SECOND BIN -- UMi\")\n",
    "Lz1, Ltot1, E1, Jtheta1, v1, snap1, rsid1, pos1, vel1 = extractActions(conn, hMass_bins[1], hMass_bins[2], sun_pos, hpos, hvel, rotmat, radius)\n",
    "print(\"THIRD BIN -- Scl\")\n",
    "Lz2, Ltot2, E2, Jtheta2, v2, snap2, rsid2, pos2, vel2 = extractActions(conn, hMass_bins[2], hMass_bins[3], sun_pos, hpos, hvel, rotmat, radius)\n",
    "print(\"FOURTH BIN -- Fnx\")\n",
    "Lz3, Ltot3, E3, Jtheta3, v3, snap3, rsid3, pos3, vel3 = extractActions(conn, hMass_bins[3], hMass_bins[4], sun_pos, hpos, hvel, rotmat, radius)\n",
    "print(\"FIFTH BIN -- Sag\")\n",
    "Lz4, Ltot4, E4, Jtheta4, v4, snap4, rsid4, pos4, vel4 = extractActions(conn, hMass_bins[4], hMass_bins[5], sun_pos, hpos, hvel, rotmat, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizing output a bit for plotting\n",
    "\n",
    "Lzs = [Lz0,Lz1,Lz2,Lz3,Lz4]\n",
    "Ltots = [Ltot0,Ltot1,Ltot2,Ltot3,Ltot4]\n",
    "Jths = [Jtheta0,Jtheta1,Jtheta2,Jtheta3,Jtheta4]\n",
    "vs = [v0,v1,v2,v3,v4]\n",
    "snaps = [snap0,snap1,snap2,snap3,snap4]\n",
    "rsids = [rsid0,rsid1,rsid2,rsid3,rsid4]\n",
    "pos = [pos0,pos1,pos2,pos3,pos4]\n",
    "vel = [vel0,vel1,vel2,vel3,vel4]\n",
    "labs = [r'$<10^5 M_{\\odot}$',r'$10^{5-6} M_{\\odot}$',r'$10^{6-7} M_{\\odot}$',r'$10^{7-8} M_{\\odot}$',r'$>10^{8} M_{\\odot}$']\n",
    "\n",
    "# calculating all infall redshifts/times takes a bit of time, so I am only saving the UFD ones for now\n",
    "# could save all of them by uncommenting bottom lines\n",
    "redshifts = [haloutils.get_z_snap(hpath,snap0)]\n",
    "times = [haloutils.get_t_snap(hpath,snap0)]\n",
    "# redshifts = [haloutils.get_z_snap(hpath,snap0),haloutils.get_z_snap(hpath,snap1),haloutils.get_z_snap(hpath,snap2),haloutils.get_z_snap(hpath,snap3),haloutils.get_z_snap(hpath,snap4)]\n",
    "# times = [haloutils.get_t_snap(hpath,snap0),haloutils.get_t_snap(hpath,snap1),haloutils.get_t_snap(hpath,snap2),haloutils.get_t_snap(hpath,snap3),haloutils.get_t_snap(hpath,snap4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy offset\n",
    "# (since the energies stored in the database have large, arbitrary offsets)\n",
    "Emin = np.min([np.min(np.append(E0,np.inf)),np.min(np.append(E1,np.inf)),np.min(np.append(E2,np.inf)),np.min(np.append(E3,np.inf)),np.min(np.append(E4,np.inf))])\n",
    "Es = [E0-Emin,E1-Emin,E2-Emin,E3-Emin,E4-Emin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTED: all particles, colored by halo_mass\n",
    "\n",
    "dataPanda = []\n",
    "for i in range(5-1,-1,-1):\n",
    "    trace = go.Scattergl(\n",
    "        y = Es[i],\n",
    "        x = Lzs[i],\n",
    "        mode='markers',\n",
    "        name=labs[i],\n",
    "        marker=dict(\n",
    "            size=4\n",
    "        ))\n",
    "    dataPanda.append(trace) \n",
    "\n",
    "layout=go.Layout(\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=700,\n",
    "    xaxis_title='Lz [Mpc*km/s]',\n",
    "    yaxis_title='E [km^2/s^2]',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=dataPanda, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTED: infall\n",
    "\n",
    "shuffler = np.random.permutation(len(Es[0]))\n",
    "E_shuffle = Es[0][shuffler]\n",
    "Lz_shuffle = Lzs[0][shuffler]\n",
    "t_shuffle = times[0][shuffler]\n",
    "\n",
    "data=go.Scattergl(\n",
    "    y = E_shuffle,\n",
    "    x = Lz_shuffle,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=t_shuffle, # set color equal to a variable\n",
    "        colorscale='plasma_r', # one of plotly colorscales\n",
    "        showscale=True,\n",
    "        colorbar_title='infall time [Gyr]',\n",
    "        opacity=0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "layout=go.Layout(\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=700,\n",
    "    xaxis_title='Lz [Mpc*km/s]',\n",
    "    yaxis_title='E [km^2/s^2]'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTED: halos // true clumps\n",
    "\n",
    "def plot_true_clumps(massrange, xplot, yplot):\n",
    "    d = {'E': Es[massrange], 'Lz': Lzs[massrange], 'Ltot': Ltots[massrange], 'Jtheta': Jths[massrange], 'rsid': rsids[massrange]}\n",
    "    df = pd.DataFrame(d)\n",
    "\n",
    "    unique_rsids = np.unique(rsids[massrange])\n",
    "    dataPanda = []\n",
    "    for un_rsid in unique_rsids:\n",
    "        trace = go.Scattergl(\n",
    "            y = df[yplot][df.rsid == un_rsid],\n",
    "            x = df[xplot][df.rsid == un_rsid],\n",
    "            mode='markers',\n",
    "            name=str(int(un_rsid)),\n",
    "            marker=dict(\n",
    "                size=4\n",
    "            ))\n",
    "        dataPanda.append(trace) \n",
    "\n",
    "    layout=go.Layout(\n",
    "        autosize=False,\n",
    "        width=600,\n",
    "        height=700,\n",
    "        xaxis_title=xplot,\n",
    "        yaxis_title=yplot\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=dataPanda, layout=layout)\n",
    "    fig.show()\n",
    "    \n",
    "plot_true_clumps(0,'Lz','E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering the particles based on their actions\n",
    "\n",
    "massrange = 0\n",
    "n_cluster = 100 # how to choose this a priori?\n",
    "\n",
    "d = {'E': Es[massrange], 'Lz': Lzs[massrange], 'Ltot': Ltots[massrange], 'Jtheta': Jths[massrange], 'rsid': rsids[massrange]}\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "# clustering based on three actions: E, Jtheta, & Jphi = -Lz\n",
    "to_cl = normToCluster(df[['E','Lz','Jtheta']]).values\n",
    "\n",
    "# Traditional simple clustering algos\n",
    "ac = AgglomerativeClustering(n_clusters=n_cluster).fit(to_cl)\n",
    "print('finished Agglom')\n",
    "ap = AffinityPropagation().fit(to_cl)\n",
    "print('finished Affinity')\n",
    "ms = MeanShift(bandwidth = 0.1).fit(to_cl) # bandwidth -- how to choose parameter?\n",
    "print('finished MeanShift')\n",
    "km = KMeans(n_clusters=n_cluster).fit(to_cl)\n",
    "print('finished KMeans')\n",
    "gmm = GaussianMixture(n_components=n_cluster).fit(to_cl)\n",
    "print('finished Gaussian')\n",
    "gmm_labels = gmm.predict(to_cl)\n",
    "\n",
    "# HDBSCAN clustering\n",
    "min_cluster_size=5 # how to choose this a priori?\n",
    "hdbscan_clusterer = hdbscan.HDBSCAN(algorithm='best', alpha=1.0, approx_min_span_tree=True,\n",
    "    gen_min_span_tree=False,\n",
    "    metric='euclidean', min_cluster_size=min_cluster_size, min_samples=None, p=None)\n",
    "hdbscan_clusterer.fit(to_cl)\n",
    "hdbscan_labels = hdbscan_clusterer.labels_\n",
    "print('finished HDBSCAN')\n",
    "\n",
    "# FoF clustering\n",
    "linking = 0.04 # how to choose this a priori?\n",
    "groups = pyfof.friends_of_friends(to_cl, linking)\n",
    "# putting labels in the same list format as the other algorithms\n",
    "labels_fof = np.zeros(len(d['E']))\n",
    "i = 0\n",
    "for g in groups:\n",
    "    for particle in g:\n",
    "        labels_fof[particle] = i\n",
    "    i += 1\n",
    "print('finished FoF')\n",
    "\n",
    "# putting all of the labels from the different algos into one dataframe\n",
    "clus_all = pd.DataFrame(df['rsid']) # the true clusters\n",
    "clus_all['Agglom'] = ac.labels_\n",
    "clus_all['Affinity'] = ap.labels_\n",
    "clus_all['MeanSh'] = ms.labels_\n",
    "clus_all['KMeans'] = km.labels_\n",
    "clus_all['Gaussian'] = gmm_labels\n",
    "clus_all['HDBSCAN'] = hdbscan_labels\n",
    "clus_all['FoF'] = labels_fof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of clusters found by HDBSCAN: %d' % (hdbscan_labels.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_found_clusters(clustype,cl_df,df,xplot='Ltot',zplot='E',yplot='Jtheta',dim=3):\n",
    "    \n",
    "    n_clusters = np.unique(cl_df[clustype])\n",
    "    dataPanda = []\n",
    "    \n",
    "    if dim == 2:    \n",
    "        for cluster in n_clusters:\n",
    "            trace = go.Scattergl(\n",
    "                y = df[yplot][cl_df[clustype] == cluster],\n",
    "                x = df[xplot][cl_df[clustype] == cluster],\n",
    "                mode='markers',\n",
    "                name=str(cluster),\n",
    "                marker=dict(\n",
    "                    size=4\n",
    "                ))\n",
    "            dataPanda.append(trace) \n",
    "            \n",
    "        layout=go.Layout(\n",
    "            autosize=False,\n",
    "            width=600,\n",
    "            height=700,\n",
    "            xaxis_title=xplot,\n",
    "            yaxis_title=yplot\n",
    "        )\n",
    "\n",
    "    if dim == 3:\n",
    "        for cluster in n_clusters:\n",
    "            trace = go.Scatter3d(\n",
    "                y = df[yplot][cl_df[clustype] == cluster],\n",
    "                x = df[xplot][cl_df[clustype] == cluster],\n",
    "                z = df[zplot][cl_df[clustype] == cluster],\n",
    "                mode='markers',\n",
    "                name=str(cluster),\n",
    "                marker=dict(\n",
    "                    size=4\n",
    "                ))\n",
    "            dataPanda.append(trace) \n",
    "        layout=go.Layout(\n",
    "            autosize=False,\n",
    "            width=1000,\n",
    "            height=700,\n",
    "            scene = dict(\n",
    "            xaxis = dict(\n",
    "                title=xplot),\n",
    "            yaxis = dict(\n",
    "                title=yplot),\n",
    "            zaxis = dict(\n",
    "                title=zplot),),\n",
    "        )\n",
    "\n",
    "\n",
    "    fig = go.Figure(data=dataPanda, layout=layout)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_found_clusters('HDBSCAN',clus_all,df,xplot='Lz',yplot='E',dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_found_clusters('KMeans',clus_all,df,xplot='Lz',yplot='E',dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-blake",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
