{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f72df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.optim import SGD, Adam\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tools.gnn_models import GCNEdgeBased\n",
    "from tools.evaluation_metric import *\n",
    "from tools.cluster_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "train_dataset_ids = [1130025, 1195075, 1195448, 1232164, 1268839, 1292085,\\\n",
    "                    1354437, 1422331, 1422429, 1599988, 1631506, 1631582, 1725139,\\\n",
    "                    1725272, 196589, 264569, 447649, 5320, 581141, 581180, 795802,\\\n",
    "                    796175, 94638, 95289]\n",
    "\n",
    "test_dataset_ids = [1079897, 1232423, 1599902, 196078]\n",
    "\n",
    "val_dataset_ids = [1104787, 1387186, 388476, 65777]\n",
    "\n",
    "def filterer(df):\n",
    "    return df.loc[df['redshiftstar']<2].copy()\n",
    "\n",
    "feature_columns = ['estar', 'jrstar', 'jzstar', 'jphistar', 'rstar', 'vstar', 'vxstar', 'vystar', 'vzstar', 'vrstar', 'vphistar', 'phistar', 'zstar']\n",
    "position_columns = ['xstar', 'ystar', 'zstar']\n",
    "data_transforms = T.Compose(transforms=[T.KNNGraph(k=300, force_undirected=True), T.GDC(sparsification_kwargs={'avg_degree':300, 'method':'threshold'})]) #\n",
    "train_dataset = NormalCaterpillarDataset('../data/caterpillar', '0', feature_columns, position_columns, use_dataset_ids=train_dataset_ids, data_filter=filterer, repeat=10, label_column='cluster_id', transform=data_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)  # it's already pre-shuffled. We can't do shuffling here because it must generate things in sequence.\n",
    "val_dataset = NormalCaterpillarDataset('../data/caterpillar', '0', feature_columns, position_columns, use_dataset_ids=val_dataset_ids, data_filter=filterer, repeat=10, label_column='cluster_id', transform=data_transforms)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_dataset = NormalCaterpillarDataset('../data/caterpillar', '0', feature_columns, position_columns, use_dataset_ids=test_dataset_ids, data_filter=filterer, repeat=10, label_column='cluster_id', transform=data_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "model = GANOrigEdgeBased(len(feature_columns), regularizer=0).to(device)\n",
    "model.load_state_dict(torch.load('weights/GANOrigEdgeBased_model300new/100.pth')['model_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_all(n_components, loader, model):\n",
    "\tmetrics = []\n",
    "\tfor i, data_batch in enumerate(loader):\n",
    "\t\tprint(data_batch)\n",
    "\t\tdata_batch_train = data_batch.to(device)\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tmodel.eval()\n",
    "\t\t\tedge_pred = model(data_batch_train)\n",
    "\t\t\tloss = model.loss(edge_pred, data_batch_train.edge_type)\n",
    "\n",
    "\t\tadj = torch.sparse_coo_tensor(data_batch.edge_index.cpu(), edge_pred.cpu(), (len(data_batch.x), len(data_batch.x))).to_dense()\n",
    "\t\tFX = C_Spectral(adj, n_components=n_components)\n",
    "\n",
    "\t\tmetric = ClusterEvalAll(FX, data_batch['y'].cpu().numpy())()\n",
    "\t\twriter.add_scalar('IoU_TP', metric['IoU_TP'], 4000*i)\n",
    "\t\twriter.add_scalar('IoU_recall', metric['IoU_recall'], 4000*i)\n",
    "\t\twriter.add_scalar('Mode_TP', metric['Mode_TP'], 4000*i)\n",
    "\t\twriter.add_scalar('Mode_recall', metric['Mode_recall'], 4000*i)\n",
    "\t\twriter.add_scalar('ModeProb_TP', metric['ModeProb_TP'], 4000*i)\n",
    "\t\twriter.add_scalar('ModeProb_recall', metric['ModeProb_recall'], 4000*i)\n",
    "\n",
    "\t\t\n",
    "\t\tprint()\n",
    "\t\tprint('current metric:')\n",
    "\t\tprint(metric)\n",
    "\t\tprint()\n",
    "\t\tmetrics.append(metric)\n",
    "\tf_metric = ClusterEvalAll.aggregate(metrics)\n",
    "\treturn f_metric\n",
    "\n",
    "results = {}\n",
    "for n_components in [5, 10, 20, 30, 40, 50, 60, 70, 80, 100]:\n",
    "\tmetric = evaluate_all(n_components, test_loader, model)\n",
    "\tresults[n_components] = metric\n",
    "\n",
    "with open('../results/SpectralEdge2Cluster_test_GANOrig_100.json', 'w') as f:\n",
    "\tjson.dump(results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
